{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAqiR4jSCxcq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from numpy import zeros\n",
        "from numpy.random import randint\n",
        "\n",
        "# Data\n",
        "from tensorflow.image import resize\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Data Viz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model\n",
        "from keras.layers import add\n",
        "from keras.layers import Input\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import multiply\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.models import load_model\n",
        "# Model Functions\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "\n",
        "def load_image(path):\n",
        "    img = resize(img_to_array(load_img(path))/255., (256,256))\n",
        "    return img\n",
        "\n",
        "def load_data(paths):\n",
        "    images = zeros(shape=(len(paths), 256,256,3))\n",
        "    masks = zeros(shape=(len(paths), 256,256,3))\n",
        "    for i, path in tqdm(enumerate(paths), desc=\"Loading\"):\n",
        "        image = load_image(path)\n",
        "        images[i] = image\n",
        "    return images\n",
        "\n",
        "def show_image(image, title=None):\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "class Encoder(Layer):\n",
        "\n",
        "    def __init__(self, filters, rate, pooling=True, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.filters = filters\n",
        "        self.rate = rate\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.bn = BatchNormalization()\n",
        "        self.c1 = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer=\"he_normal\")\n",
        "        self.drop = Dropout(rate)\n",
        "        self.c2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu', kernel_initializer=\"he_normal\")\n",
        "        self.pool = MaxPool2D()\n",
        "\n",
        "    def call(self, X):\n",
        "        x = self.bn(X)\n",
        "        x = self.c1(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.c2(x)\n",
        "        if self.pooling:\n",
        "            y = self.pool(x)\n",
        "            return y, x\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"filters\":self.filters,\n",
        "            \"rate\":self.rate,\n",
        "            \"pooling\":self.pooling\n",
        "        }\n",
        "\n",
        "class Decoder(Layer):\n",
        "\n",
        "    def __init__(self, filters, rate, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.filters = filters\n",
        "        self.rate = rate\n",
        "\n",
        "        self.bn = BatchNormalization()\n",
        "        self.cT = Conv2DTranspose(filters, kernel_size=3, strides=2, padding='same', activation='relu', kernel_initializer=\"he_normal\")\n",
        "        self.net = Encoder(filters, rate, pooling=False)\n",
        "\n",
        "    def call(self, X):\n",
        "        x, skip_x = X\n",
        "        x = self.bn(x)\n",
        "        x = self.cT(x)\n",
        "        x = concatenate([x, skip_x])\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"filters\":self.filters,\n",
        "            \"rate\":self.rate,\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def resize_image(input_path, output_path, target_size):\n",
        "    # Open the source image\n",
        "    source_image = Image.open(input_path)\n",
        "\n",
        "    # Resize the source image to the target size\n",
        "    resized_image = source_image.resize(target_size, Image.ANTIALIAS)\n",
        "\n",
        "    # Save the resized image to the output path\n",
        "    resized_image.save(output_path)\n",
        "\n",
        "# Example usage\n",
        "source_image_path = \"/content/drive/MyDrive/training_dataset/test/demoans/output12.jpg\"\n",
        "target_image_path = \"/content/drive/MyDrive/training_dataset/test/demo/input12.jpg\"\n",
        "\n",
        "# Open the target image to get its dimensions\n",
        "target_image = Image.open(target_image_path)\n",
        "target_size = target_image.size\n",
        "\n",
        "# Resize the source image to match the target size\n",
        "resize_image(source_image_path, \"/content/drive/MyDrive/output12.jpg\", target_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypl2J266w4kq",
        "outputId": "70871243-817a-47c3-8d4b-a359eaaad0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-2c4d9ce1245e>:8: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  resized_image = source_image.resize(target_size, Image.ANTIALIAS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"drive/MyDrive/training_dataset/test/demo\"\n",
        "total_images = len(os.listdir(image_path))\n",
        "print(f\"Total Number of Images : {total_images}\")\n",
        "\n",
        "all_image_paths = sorted(glob(image_path + \"/*.jpg\"))\n",
        "\n",
        "test_paths = all_image_paths[:]\n",
        "X_test = load_data(test_paths)\n",
        "\n",
        "unet_inputs = Input(shape=(256,256,3), name=\"UNetInput\")\n",
        "\n",
        "# Encoder Network : Downsampling phase\n",
        "p1, c1 = Encoder(64, 0.1, name=\"Encoder1\")(unet_inputs)\n",
        "p2, c2 = Encoder(128, 0.1, name=\"Encoder2\")(p1)\n",
        "p3, c3 = Encoder(256, 0.2, name=\"Encoder3\")(p2)\n",
        "p4, c4 = Encoder(512, 0.2, name=\"Encoder4\")(p3)\n",
        "\n",
        "\n",
        "# Encoding Layer : Latent Representation\n",
        "e = Encoder(512, 0.3, pooling=False)(p4)\n",
        "\n",
        "# Attention + Decoder Network : Upsampling phase.\n",
        "d1 = Decoder(512, 0.2, name=\"Decoder1\")([e, c4])\n",
        "d2 = Decoder(256, 0.2, name=\"Decoder2\")([d1, c3])\n",
        "d3 = Decoder(128, 0.1, name=\"Decoder3\")([d2, c2])\n",
        "d4 = Decoder(64, 0.1, name=\"Decoder4\")([d3, c1])\n",
        "\n",
        "# Output\n",
        "unet_out = Conv2D(3, kernel_size=3, padding='same', activation='sigmoid')(d4)\n",
        "\n",
        "# Model\n",
        "UNet = Model(\n",
        "    inputs=unet_inputs,\n",
        "    outputs=unet_out,\n",
        "    name=\"AttentionUNet\"\n",
        ")\n",
        "\n",
        "# Compiling\n",
        "UNet.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam'\n",
        ")\n",
        "\n",
        "#load weight\n",
        "\n",
        "UNet.load_weights('drive/MyDrive/training_dataset/segmodel.h5')"
      ],
      "metadata": {
        "id": "P6YlZz9QDF1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512b2a17-72fb-4545-8c35-5458d80c25d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Images : 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: 12it [00:00, 17.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNet.load_weights('drive/MyDrive/training_dataset/segmodel.h5')"
      ],
      "metadata": {
        "id": "r3JQ4UGyKdC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from random import randint\n",
        "\n",
        "for id in range(12):\n",
        "    image = X_test[id]\n",
        "    pred_mask = UNet.predict(tf.expand_dims(image, axis=0))[0]\n",
        "    post_process = (pred_mask[:, :, 0] > 0.66)\n",
        "\n",
        "    plt.figure()  # Create a new figure for each post-processed mask\n",
        "    plt.imshow(post_process, cmap='gray')  # Display post-processed mask in grayscale\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig(f'/content/drive/MyDrive/training_dataset/test/demoans/output{id+1}.jpg', bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoKwCo2_Atce",
        "outputId": "0f0b6988-f630-4d8a-c605-cd5e0853e991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ]
    }
  ]
}